{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytorch3d\n",
    "from pytorch3d.io import load_objs_as_meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj_vertex_data(obj_file_path):\n",
    "    # 使用 PyTorch3D 来加载 .obj 文件\n",
    "    meshes = load_objs_as_meshes([obj_file_path])\n",
    "    \n",
    "    # 获取顶点数据\n",
    "    vertices = meshes.verts_packed().detach().cpu().numpy()\n",
    "    \n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_data(image_folder):\n",
    "    image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith('.png')]\n",
    "    images = [np.array(Image.open(file)) for file in image_files]\n",
    "    \n",
    "    # 将图像数据转换为字节数组\n",
    "    images_as_bytes = [tf.io.encode_jpeg(image).numpy().astype(np.float32) for image in images]\n",
    "    print(images_as_bytes[0])\n",
    "    return images_as_bytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(category_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m vertices \u001b[38;5;241m=\u001b[39m load_obj_vertex_data(obj_file)\n\u001b[0;32m---> 12\u001b[0m images_as_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mload_image_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images_as_bytes:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# 创建 tf.Example 并将数据序列化\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     example \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mExample(features\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mFeatures(\n\u001b[1;32m     16\u001b[0m         feature\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     17\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertices\u001b[39m\u001b[38;5;124m'\u001b[39m: tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mFeature(bytes_list\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mBytesList(value\u001b[38;5;241m=\u001b[39m[vertices\u001b[38;5;241m.\u001b[39mtobytes()])),\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m: tf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mFeature(bytes_list\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mBytesList(value\u001b[38;5;241m=\u001b[39mimg))\n\u001b[1;32m     19\u001b[0m         }\n\u001b[1;32m     20\u001b[0m     ))\n",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m, in \u001b[0;36mload_image_data\u001b[0;34m(image_folder)\u001b[0m\n\u001b[1;32m      3\u001b[0m images \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(file)) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m image_files]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 将图像数据转换为字节数组\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m images_as_bytes \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mencode_jpeg(image)\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(images_as_bytes[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m images_as_bytes\n",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m images \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(file)) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m image_files]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 将图像数据转换为字节数组\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m images_as_bytes \u001b[38;5;241m=\u001b[39m [\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_jpeg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(images_as_bytes[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m images_as_bytes\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "tfrecord_filename = 'data.tfrecord'\n",
    "\n",
    "with tf.io.TFRecordWriter(tfrecord_filename) as writer:\n",
    "    base_folder = '/media/aaron/work/KIRI/ME_1015'\n",
    "    for category_folder in os.listdir(base_folder):\n",
    "        category_path = os.path.join(base_folder, category_folder)\n",
    "        obj_file = os.path.join(category_path, 'model_align.obj')\n",
    "        \n",
    "        image_folder = os.path.join(category_path, 'images')\n",
    "        \n",
    "        vertices = load_obj_vertex_data(obj_file)\n",
    "        images_as_bytes = load_image_data(image_folder)\n",
    "        for img in images_as_bytes:\n",
    "            # 创建 tf.Example 并将数据序列化\n",
    "            example = tf.train.Example(features=tf.train.Features(\n",
    "                feature={\n",
    "                    'vertices': tf.train.Feature(bytes_list=tf.train.BytesList(value=[vertices.tobytes()])),\n",
    "                    'images': tf.train.Feature(bytes_list=tf.train.BytesList(value=img))\n",
    "                }\n",
    "            ))\n",
    "        \n",
    "        writer.write(example.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_12760/2309533413.py\", line 13, in parse_tfrecord_fn  *\n        images = tf.stack([tf.image.decode_jpeg(image, channels=3) for image in example['images']])\n\n    TypeError: 'SparseTensor' object is not iterable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m# 创建 tf.data.Dataset 以从 tfRecord 文件中读取数据\u001b[39;00m\n\u001b[1;32m     17\u001b[0m raw_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mTFRecordDataset(tfrecord_filename)\n\u001b[0;32m---> 18\u001b[0m parsed_dataset \u001b[39m=\u001b[39m raw_dataset\u001b[39m.\u001b[39;49mmap(parse_tfrecord_fn)\n\u001b[1;32m     20\u001b[0m \u001b[39m# 迭代数据并验证\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m vertices, images \u001b[39min\u001b[39;00m parsed_dataset:\n\u001b[1;32m     22\u001b[0m     \u001b[39m# 在这里，你可以进行任何你需要的验证操作\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[39m# 例如，打印顶点数据的形状和图像的数量\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2294\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2291\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2292\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2293\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2294\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39;49m, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   2295\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2296\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2297\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[1;32m   2298\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2301\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   2302\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:5499\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5498\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5499\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m   5500\u001b[0m     map_func,\n\u001b[1;32m   5501\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[1;32m   5502\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[1;32m   5503\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[1;32m   5504\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[1;32m   5505\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[1;32m   5506\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   5507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5510\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m   5511\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:263\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    257\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    261\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 263\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    264\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:226\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    218\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m   concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[1;32m    227\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    228\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    229\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:192\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mvalidate_inputs_with_signature(args, kwargs)\n\u001b[1;32m    191\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 192\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[1;32m    193\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    194\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m    195\u001b[0m       concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:157\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    155\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:360\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m    358\u001b[0m   args, kwargs \u001b[39m=\u001b[39m generalized_func_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(args, kwargs)\n\u001b[1;32m    362\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:284\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m    280\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m    281\u001b[0m ]\n\u001b[1;32m    282\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m    283\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 284\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    285\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    287\u001b[0m         args,\n\u001b[1;32m    288\u001b[0m         kwargs,\n\u001b[1;32m    289\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    290\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m    291\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m    292\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    293\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m    294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    295\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    296\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1283\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1283\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1285\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:240\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    235\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    236\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[1;32m    237\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    238\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    241\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    242\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:171\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    170\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 171\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[1;32m    172\u001b[0m ret \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filehassb_78.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__parse_tfrecord_fn\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m     11\u001b[0m example \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mparse_single_example, (ag__\u001b[39m.\u001b[39mld(example), ag__\u001b[39m.\u001b[39mld(feature_description)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m vertices \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mdecode_raw, (ag__\u001b[39m.\u001b[39mld(example)[\u001b[39m'\u001b[39m\u001b[39mvertices\u001b[39m\u001b[39m'\u001b[39m], ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mfloat32), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 13\u001b[0m images \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mstack, ([ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mdecode_jpeg, (ag__\u001b[39m.\u001b[39mld(image),), \u001b[39mdict\u001b[39m(channels\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m), fscope) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m ag__\u001b[39m.\u001b[39mld(example)[\u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m]],), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_12760/2309533413.py\", line 13, in parse_tfrecord_fn  *\n        images = tf.stack([tf.image.decode_jpeg(image, channels=3) for image in example['images']])\n\n    TypeError: 'SparseTensor' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tfrecord_filename = 'data.tfrecord'\n",
    "\n",
    "# 定义数据解析函数\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        'vertices': tf.io.FixedLenFeature([], tf.string),\n",
    "        'images': tf.io.VarLenFeature(tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    vertices = tf.io.decode_raw(example['vertices'], tf.float32)\n",
    "    images = tf.stack([tf.image.decode_jpeg(image, channels=3) for image in example['images']])\n",
    "    return vertices, images\n",
    "\n",
    "# 创建 tf.data.Dataset 以从 tfRecord 文件中读取数据\n",
    "raw_dataset = tf.data.TFRecordDataset(tfrecord_filename)\n",
    "parsed_dataset = raw_dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "# 迭代数据并验证\n",
    "for vertices, images in parsed_dataset:\n",
    "    # 在这里，你可以进行任何你需要的验证操作\n",
    "    # 例如，打印顶点数据的形状和图像的数量\n",
    "    print(\"Vertices shape:\", vertices.shape)\n",
    "    print(\"Number of images:\", images.shape[0])\n",
    "\n",
    "    # 如果需要，还可以可视化或其他验证操作\n",
    "    # 例如，显示图像、绘制顶点等\n",
    "\n",
    "    break  # 仅演示目的，仅处理第一条数据\n",
    "\n",
    "# 关闭 tf.Session\n",
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dcbfcb1d4d83ea08d125928cdb18da55676c34459c9cee50303e942e700cad0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
